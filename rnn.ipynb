{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from random import random\n",
    " \n",
    "pdata = pd.read_csv('oct_march.csv',names=['chid','views','subcriber','videocount','date']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdata=pdata.drop(pdata.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_groups=pdata.groupby('chid')\n",
    "grps=[channel_groups.get_group(x) for x in channel_groups.groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def _load_data(data, n_prev = 4):  \n",
    "    \"\"\"\n",
    "    data should be pd.DataFrame()\n",
    "    \"\"\"\n",
    "\n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data)-n_prev):\n",
    "        docX.append(data.iloc[i:i+n_prev-1].as_matrix())\n",
    "        docY.append(data.iloc[i+n_prev].as_matrix())\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "\n",
    "    return alsX, alsY\n",
    "\n",
    "def train_test_split(df, test_size=0):  \n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"\n",
    "    ntrn = round(len(df) * (1 - test_size))\n",
    "\n",
    "    X_train, y_train = _load_data(df.iloc[0:ntrn])\n",
    "\n",
    "    return (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def m():\n",
    "    in_out_neurons = 3  \n",
    "\n",
    "    hidden_neurons = 300\n",
    "\n",
    "\n",
    "    model = Sequential()  \n",
    "\n",
    "    model.add(LSTM(batch_input_shape=(1,3,3),units=hidden_neurons,use_bias=True, return_sequences=True,stateful=True)) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=150,stateful=True,use_bias=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=10,use_bias=True))  \n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=3,use_bias=True))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\") \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3s - loss: nan\n",
      "Epoch 2/3\n",
      "2s - loss: nan\n",
      "Epoch 3/3\n",
      "2s - loss: nan\n",
      "Epoch 1/3\n",
      "4s - loss: nan\n",
      "Epoch 2/3\n",
      "3s - loss: nan\n",
      "Epoch 3/3\n",
      "2s - loss: nan\n",
      "Epoch 1/3\n",
      "3s - loss: 0.0403\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0300\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0286\n",
      "Epoch 1/3\n",
      "3s - loss: 0.0274\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0268\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0205\n",
      "Epoch 1/3\n",
      "3s - loss: 0.0253\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0300\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0219\n",
      "Epoch 1/3\n",
      "3s - loss: 0.0531\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0548\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0495\n",
      "Epoch 1/3\n",
      "3s - loss: 0.0876\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0591\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0618\n",
      "Epoch 1/3\n",
      "4s - loss: 0.0657\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0478\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0393\n",
      "Epoch 1/3\n",
      "4s - loss: 0.0487\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0443\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0384\n",
      "Epoch 1/3\n",
      "4s - loss: 0.0360\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0414\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0398\n",
      "Epoch 1/3\n",
      "4s - loss: 0.0250\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0268\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0257\n",
      "Epoch 1/3\n",
      "4s - loss: nan\n",
      "Epoch 2/3\n",
      "2s - loss: nan\n",
      "Epoch 3/3\n",
      "3s - loss: nan\n",
      "Epoch 1/3\n",
      "4s - loss: 0.0609\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0549\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0462\n",
      "Epoch 1/3\n",
      "5s - loss: nan\n",
      "Epoch 2/3\n",
      "3s - loss: nan\n",
      "Epoch 3/3\n",
      "3s - loss: nan\n",
      "Epoch 1/3\n",
      "5s - loss: 0.0680\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0623\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0593\n",
      "Epoch 1/3\n",
      "5s - loss: 0.0412\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0340\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0337\n",
      "Epoch 1/3\n",
      "5s - loss: 0.0309\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0311\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0287\n",
      "Epoch 1/3\n",
      "4s - loss: nan\n",
      "Epoch 2/3\n",
      "2s - loss: nan\n",
      "Epoch 3/3\n",
      "2s - loss: nan\n",
      "Epoch 1/3\n",
      "8s - loss: 0.0254\n",
      "Epoch 2/3\n",
      "4s - loss: 0.0200\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0265\n",
      "Epoch 1/3\n",
      "6s - loss: nan\n",
      "Epoch 2/3\n",
      "3s - loss: nan\n",
      "Epoch 3/3\n",
      "3s - loss: nan\n",
      "Epoch 1/3\n",
      "5s - loss: 0.0521\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0454\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0549\n",
      "Epoch 1/3\n",
      "3s - loss: nan\n",
      "Epoch 2/3\n",
      "0s - loss: nan\n",
      "Epoch 3/3\n",
      "0s - loss: nan\n",
      "Epoch 1/3\n",
      "5s - loss: 0.0534\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0467\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0543\n",
      "Epoch 1/3\n",
      "3s - loss: nan\n",
      "Epoch 2/3\n",
      "0s - loss: nan\n",
      "Epoch 3/3\n",
      "0s - loss: nan\n",
      "Epoch 1/3\n",
      "5s - loss: nan\n",
      "Epoch 2/3\n",
      "2s - loss: nan\n",
      "Epoch 3/3\n",
      "3s - loss: nan\n",
      "Epoch 1/3\n",
      "6s - loss: 0.0288\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0367\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0362\n",
      "Epoch 1/3\n",
      "6s - loss: nan\n",
      "Epoch 2/3\n",
      "3s - loss: nan\n",
      "Epoch 3/3\n",
      "3s - loss: nan\n",
      "Epoch 1/3\n",
      "5s - loss: 0.0345\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0258\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0267\n",
      "Epoch 1/3\n",
      "7s - loss: 0.0285\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0221\n",
      "Epoch 3/3\n",
      "4s - loss: 0.0208\n",
      "Epoch 1/3\n",
      "7s - loss: 0.0433\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0435\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0369\n",
      "Epoch 1/3\n",
      "6s - loss: 0.0318\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0297\n",
      "Epoch 3/3\n",
      "4s - loss: 0.0297\n",
      "Epoch 1/3\n",
      "9s - loss: 0.0473\n",
      "Epoch 2/3\n",
      "4s - loss: 0.0314\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0351\n",
      "Epoch 1/3\n",
      "7s - loss: nan\n",
      "Epoch 2/3\n",
      "3s - loss: nan\n",
      "Epoch 3/3\n",
      "3s - loss: nan\n",
      "Epoch 1/3\n",
      "5s - loss: nan\n",
      "Epoch 2/3\n",
      "2s - loss: nan\n",
      "Epoch 3/3\n",
      "3s - loss: nan\n",
      "Epoch 1/3\n",
      "7s - loss: 0.0394\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0337\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0370\n",
      "Epoch 1/3\n",
      "7s - loss: 0.0560\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0525\n",
      "Epoch 3/3\n",
      "4s - loss: 0.0442\n",
      "Epoch 1/3\n",
      "7s - loss: 0.0228\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0255\n",
      "Epoch 3/3\n",
      "4s - loss: 0.0295\n",
      "Epoch 1/3\n",
      "11s - loss: nan\n",
      "Epoch 2/3\n",
      "3s - loss: nan\n",
      "Epoch 3/3\n",
      "3s - loss: nan\n",
      "Epoch 1/3\n",
      "6s - loss: 0.0343\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0342\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0343\n",
      "Epoch 1/3\n",
      "4s - loss: 0.0709\n",
      "Epoch 2/3\n",
      "0s - loss: 0.0686\n",
      "Epoch 3/3\n",
      "0s - loss: 0.0666\n",
      "Epoch 1/3\n",
      "9s - loss: 0.0158\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0135\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0110\n",
      "Epoch 1/3\n",
      "9s - loss: nan\n",
      "Epoch 2/3\n",
      "5s - loss: nan\n",
      "Epoch 3/3\n",
      "6s - loss: nan\n",
      "Epoch 1/3\n",
      "10s - loss: 0.0314\n",
      "Epoch 2/3\n",
      "4s - loss: 0.0285\n",
      "Epoch 3/3\n",
      "4s - loss: 0.0290\n",
      "Epoch 1/3\n",
      "10s - loss: 0.0675\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0621\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0550\n",
      "Epoch 1/3\n",
      "9s - loss: nan\n",
      "Epoch 2/3\n",
      "5s - loss: nan\n",
      "Epoch 3/3\n",
      "5s - loss: nan\n",
      "Epoch 1/3\n",
      "9s - loss: nan\n",
      "Epoch 2/3\n",
      "3s - loss: nan\n",
      "Epoch 3/3\n",
      "3s - loss: nan\n",
      "Epoch 1/3\n",
      "10s - loss: nan\n",
      "Epoch 2/3\n",
      "4s - loss: nan\n",
      "Epoch 3/3\n",
      "6s - loss: nan\n",
      "Epoch 1/3\n",
      "10s - loss: 0.0618\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0561\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0590\n",
      "Epoch 1/3\n",
      "11s - loss: 0.0370\n",
      "Epoch 2/3\n",
      "8s - loss: 0.0379\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0403\n",
      "Epoch 1/3\n",
      "7s - loss: 0.0350\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0341\n",
      "Epoch 3/3\n",
      "6s - loss: 0.0286\n",
      "Epoch 1/3\n",
      "13s - loss: 0.0651\n",
      "Epoch 2/3\n",
      "6s - loss: 0.0563\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0592\n",
      "Epoch 1/3\n",
      "11s - loss: 0.0364\n",
      "Epoch 2/3\n",
      "6s - loss: 0.0377\n",
      "Epoch 3/3\n",
      "6s - loss: 0.0319\n",
      "Epoch 1/3\n",
      "11s - loss: 0.0366\n",
      "Epoch 2/3\n",
      "8s - loss: 0.0378\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0332\n",
      "Epoch 1/3\n",
      "11s - loss: 0.0430\n",
      "Epoch 2/3\n",
      "7s - loss: 0.0458\n",
      "Epoch 3/3\n",
      "8s - loss: 0.0422\n",
      "Epoch 1/3\n",
      "11s - loss: 0.0501\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0463\n",
      "Epoch 3/3\n",
      "9s - loss: 0.0370\n",
      "Epoch 1/3\n",
      "10s - loss: nan\n",
      "Epoch 2/3\n",
      "7s - loss: nan\n",
      "Epoch 3/3\n",
      "8s - loss: nan\n",
      "Epoch 1/3\n",
      "10s - loss: 0.0565\n",
      "Epoch 2/3\n",
      "11s - loss: 0.0489\n",
      "Epoch 3/3\n",
      "9s - loss: 0.0493\n",
      "Epoch 1/3\n",
      "12s - loss: 0.0285\n",
      "Epoch 2/3\n",
      "6s - loss: 0.0552\n",
      "Epoch 3/3\n",
      "7s - loss: 0.0492\n",
      "Epoch 1/3\n",
      "12s - loss: 0.0477\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0435\n",
      "Epoch 3/3\n",
      "7s - loss: 0.0458\n",
      "Epoch 1/3\n",
      "13s - loss: 0.0228\n",
      "Epoch 2/3\n",
      "7s - loss: 0.0212\n",
      "Epoch 3/3\n",
      "7s - loss: 0.0231\n",
      "Epoch 1/3\n",
      "14s - loss: 0.0246\n",
      "Epoch 2/3\n",
      "9s - loss: 0.0248\n",
      "Epoch 3/3\n",
      "8s - loss: 0.0262\n",
      "Epoch 1/3\n",
      "11s - loss: 0.0664\n",
      "Epoch 2/3\n",
      "8s - loss: 0.0603\n",
      "Epoch 3/3\n",
      "8s - loss: 0.0640\n",
      "Epoch 1/3\n",
      "12s - loss: nan\n",
      "Epoch 2/3\n",
      "9s - loss: nan\n",
      "Epoch 3/3\n",
      "6s - loss: nan\n",
      "Epoch 1/3\n",
      "14s - loss: 0.0455\n",
      "Epoch 2/3\n",
      "6s - loss: 0.0428\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0421\n",
      "Epoch 1/3\n",
      "12s - loss: nan\n",
      "Epoch 2/3\n",
      "7s - loss: nan\n",
      "Epoch 3/3\n",
      "6s - loss: nan\n",
      "Epoch 1/3\n",
      "12s - loss: nan\n",
      "Epoch 2/3\n",
      "8s - loss: nan\n",
      "Epoch 3/3\n",
      "6s - loss: nan\n",
      "Epoch 1/3\n",
      "14s - loss: 0.0266\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0297\n",
      "Epoch 3/3\n",
      "8s - loss: 0.0276\n",
      "Epoch 1/3\n",
      "14s - loss: 0.0398\n",
      "Epoch 2/3\n",
      "7s - loss: 0.0450\n",
      "Epoch 3/3\n",
      "6s - loss: 0.0402\n",
      "Epoch 1/3\n",
      "14s - loss: nan\n",
      "Epoch 2/3\n",
      "7s - loss: nan\n",
      "Epoch 3/3\n",
      "6s - loss: nan\n",
      "Epoch 1/3\n",
      "18s - loss: 0.0535\n",
      "Epoch 2/3\n",
      "7s - loss: 0.0462\n",
      "Epoch 3/3\n",
      "6s - loss: 0.0554\n",
      "Epoch 1/3\n",
      "13s - loss: 0.0582\n",
      "Epoch 2/3\n",
      "6s - loss: 0.0551\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0569\n",
      "Epoch 1/3\n",
      "10s - loss: 0.0422\n",
      "Epoch 2/3\n",
      "1s - loss: 0.0392\n",
      "Epoch 3/3\n",
      "1s - loss: 0.0621\n",
      "Epoch 1/3\n",
      "10s - loss: 0.0393\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0535\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0557\n",
      "Epoch 1/3\n",
      "13s - loss: 0.0271\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0215\n",
      "Epoch 3/3\n",
      "7s - loss: 0.0244\n",
      "Epoch 1/3\n",
      "17s - loss: 0.0309\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0335\n",
      "Epoch 3/3\n",
      "6s - loss: 0.0336\n",
      "Epoch 1/3\n",
      "17s - loss: 0.0368\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0320\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0362\n",
      "Epoch 1/3\n",
      "15s - loss: nan\n",
      "Epoch 2/3\n",
      "7s - loss: nan\n",
      "Epoch 3/3\n",
      "7s - loss: nan\n",
      "Epoch 1/3\n",
      "9s - loss: 0.0358\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0330\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0340\n",
      "Epoch 1/3\n",
      "18s - loss: 0.0321\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0294\n",
      "Epoch 3/3\n",
      "6s - loss: 0.0283\n",
      "Epoch 1/3\n",
      "13s - loss: 0.0525\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0461\n",
      "Epoch 3/3\n",
      "4s - loss: 0.0355\n",
      "Epoch 1/3\n",
      "13s - loss: 0.0355\n",
      "Epoch 2/3\n",
      "8s - loss: 0.0384\n",
      "Epoch 3/3\n",
      "7s - loss: 0.0393\n",
      "Epoch 1/3\n",
      "15s - loss: nan\n",
      "Epoch 2/3\n",
      "7s - loss: nan\n",
      "Epoch 3/3\n",
      "6s - loss: nan\n",
      "Epoch 1/3\n",
      "16s - loss: 0.0254\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0282\n",
      "Epoch 3/3\n",
      "9s - loss: 0.0269\n",
      "Epoch 1/3\n",
      "16s - loss: nan\n",
      "Epoch 2/3\n",
      "6s - loss: nan\n",
      "Epoch 3/3\n",
      "10s - loss: nan\n",
      "Epoch 1/3\n",
      "20s - loss: 0.0276\n",
      "Epoch 2/3\n",
      "7s - loss: 0.0321\n",
      "Epoch 3/3\n",
      "9s - loss: 0.0317\n",
      "Epoch 1/3\n",
      "15s - loss: 0.0357\n",
      "Epoch 2/3\n",
      "8s - loss: 0.0367\n",
      "Epoch 3/3\n",
      "12s - loss: 0.0317\n",
      "Epoch 1/3\n",
      "19s - loss: nan\n",
      "Epoch 2/3\n",
      "5s - loss: nan\n",
      "Epoch 3/3\n",
      "5s - loss: nan\n",
      "Epoch 1/3\n",
      "16s - loss: nan\n",
      "Epoch 2/3\n",
      "4s - loss: nan\n",
      "Epoch 3/3\n",
      "5s - loss: nan\n",
      "Epoch 1/3\n",
      "72s - loss: 0.0452\n",
      "Epoch 2/3\n",
      "8s - loss: 0.0358\n",
      "Epoch 3/3\n",
      "8s - loss: 0.0335\n",
      "Epoch 1/3\n",
      "14s - loss: 0.0301\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0283\n",
      "Epoch 3/3\n",
      "8s - loss: 0.0258\n",
      "Epoch 1/3\n",
      "16s - loss: nan\n",
      "Epoch 2/3\n",
      "5s - loss: nan\n",
      "Epoch 3/3\n",
      "5s - loss: nan\n",
      "Epoch 1/3\n",
      "15s - loss: 0.0328\n",
      "Epoch 2/3\n",
      "7s - loss: 0.0320\n",
      "Epoch 3/3\n",
      "7s - loss: 0.0395\n",
      "Epoch 1/3\n",
      "10s - loss: 0.0521\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0495\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0466\n",
      "Epoch 1/3\n",
      "13s - loss: 0.0512\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0466\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0490\n",
      "Epoch 1/3\n",
      "10s - loss: 0.0284\n",
      "Epoch 2/3\n",
      "3s - loss: 0.0259\n",
      "Epoch 3/3\n",
      "3s - loss: 0.0248\n",
      "Epoch 1/3\n",
      "12s - loss: 0.0382\n",
      "Epoch 2/3\n",
      "4s - loss: 0.0360\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0465\n",
      "Epoch 1/3\n",
      "16s - loss: nan\n",
      "Epoch 2/3\n",
      "7s - loss: nan\n",
      "Epoch 3/3\n",
      "6s - loss: nan\n",
      "Epoch 1/3\n",
      "15s - loss: 0.0481\n",
      "Epoch 2/3\n",
      "7s - loss: 0.0454\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0479\n",
      "Epoch 1/3\n",
      "17s - loss: 0.0429\n",
      "Epoch 2/3\n",
      "5s - loss: 0.0445\n",
      "Epoch 3/3\n",
      "6s - loss: 0.0367\n",
      "Epoch 1/3\n",
      "15s - loss: 0.0396\n",
      "Epoch 2/3\n",
      "6s - loss: 0.0404\n",
      "Epoch 3/3\n",
      "5s - loss: 0.0381\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Activation,Dropout \n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "import numpy as np\n",
    "l=np.ndarray((len(grps),3,2))\n",
    "for i in range(len(grps)):\n",
    "    p=grps[i]\n",
    "    p=p.sort_values(by='date')\n",
    "    del p['date']\n",
    "    del p['chid']\n",
    "    p['views']=p.views.astype(int)\n",
    "    l[i][0][0]=p['views'].max()- p['views'].min()\n",
    "    l[i][0][1]=np.asarray(p['views'], dtype=np.float).mean()\n",
    "    p['views']= (p['views'] - l[i][0][1] )/ l[i][0][0]\n",
    "    p['subcriber']=p['subcriber'].astype(int)\n",
    "    l[i][1][0]=p['subcriber'].max() - p['subcriber'].min()\n",
    "    l[i][1][1]=np.asarray(p['subcriber'], dtype=np.float).mean()\n",
    "    p['subcriber']= (p['subcriber'] - np.asarray(p['subcriber'], dtype=np.float).mean()) / (p['subcriber'].max() - p['subcriber'].min())\n",
    "    p['videocount']=p['videocount'].astype(int)\n",
    "    l[i][2][0]=p['videocount'].max() - p['videocount'].min()\n",
    "    l[i][2][1]=np.asarray(p['videocount'], dtype=np.float).mean()\n",
    "    p['videocount']= (p['videocount'] - np.asarray(p['videocount'], dtype=np.float).mean()) / (p['videocount'].max() - p['videocount'].min())\n",
    "    (X_train, y_train)= train_test_split(p)  # retrieve data\n",
    "    X_train=X_train.reshape((-1,3,3))\n",
    "    M=m() \n",
    "    M.fit(x=X_train, y=y_train,batch_size=1,epochs=3, verbose=2,shuffle=False) \n",
    "    M.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/tensorflowcpu/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/shubham/anaconda3/envs/tensorflowcpu/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/shubham/anaconda3/envs/tensorflowcpu/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for UC60GHVk_6ddgqhHwcg\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from datetime import timedelta, date\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "start_date = date(2017, 4, 1)\n",
    "end_date = date(2017, 7, 1)\n",
    "p=np.empty((10*31,3,3))\n",
    "predicted=np.ndarray((10*31,3))\n",
    "validation=np.empty((10*31,3))\n",
    "g=grps[0]\n",
    "g['views']=g.views.astype(int)\n",
    "g['subcriber']=g.subcriber.astype(int)\n",
    "g['videocount']=g.videocount.astype(int)\n",
    "X=g.sort_values(by='date')\n",
    "print (\"prediction for \"+X['chid'].values[0])\n",
    "del g['date']\n",
    "del g['chid']\n",
    "del X['date']\n",
    "del X['chid']\n",
    "M.reset_states()\n",
    "X=X.head(3)\n",
    "p[0]=X.values.reshape((1,3,3))\n",
    "i=1\n",
    "for k in range(3):\n",
    "    validation[k]=(X.values)[k]\n",
    "for single_date in daterange(date(2016,10,1), date(2017,3,31)):\n",
    "    p[i][0]=p[i-1][1]\n",
    "    p[i][1]=p[i-1][2]\n",
    "    p[i][2]=M.predict(p[i-1].reshape((1,3,3)))\n",
    "    validation[i+3]=p[i][2]\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/tensorflowcpu/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rmse of predicted values is(nan+nanj)\n",
      "2017-04-01 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-02 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-03 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-04 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-05 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-06 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-07 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-08 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-09 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-10 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-11 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-12 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-13 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-14 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-15 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-16 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-17 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-18 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-19 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-20 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-21 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-22 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-23 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-24 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-25 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-26 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-27 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-28 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-29 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-04-30 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-01 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-02 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-03 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-04 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-05 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-06 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-07 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-08 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-09 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-10 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-11 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-12 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-13 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-14 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-15 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-16 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-17 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-18 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-19 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-20 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-21 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-22 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-23 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-24 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-25 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-26 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-27 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-28 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-29 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-30 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-05-31 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-01 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-02 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-03 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-04 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-05 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-06 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-07 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-08 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-09 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-10 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-11 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-12 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-13 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-14 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-15 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-16 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-17 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-18 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-19 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-20 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-21 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-22 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-23 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-24 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-25 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-26 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-27 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-28 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-29 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n",
      "2017-06-30 [  3.89076881e+06   2.80537843e+05   7.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from cmath import sqrt\n",
    "sqr_err=0\n",
    "n=np.ndarray(3)\n",
    "for x in range(i):\n",
    "    n[0]=((g.values)[x][0]-l[0][0][1])/l[0][0][0]\n",
    "    n[1]=((g.values)[x][1]-l[0][1][1])/l[0][1][0]\n",
    "    n[2]=((g.values)[x][2]-l[0][2][1])/l[0][2][0]\n",
    "    sqr_err+=(n-validation[x])**2\n",
    "mse=np.mean(sqr_err)\n",
    "rmse=mse**0.5\n",
    "print (\"the rmse of predicted values is\"+ str(rmse))\n",
    "j=0\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    p[i][0]=p[i-1][1]\n",
    "    p[i][1]=p[i-1][2]\n",
    "    p[i][2]=M.predict(p[i-1].reshape((1,3,3)))\n",
    "    predicted[j][0]=p[i][2][0]*l[0][0][0]+l[0][0][1]\n",
    "    predicted[j][1]=p[i][2][1]*l[0][1][0]+l[0][1][1]\n",
    "    predicted[j][2]=p[i][2][2]*l[0][2][0]+l[0][2][1]\n",
    "    print (single_date,predicted[j])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
