{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from random import random\n",
    " \n",
    "pdata = pd.read_csv('oct_march.csv',names=['chid','views','subcriber','videocount','date']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chid</th>\n",
       "      <th>views</th>\n",
       "      <th>subcriber</th>\n",
       "      <th>videocount</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3302429</td>\n",
       "      <td>2087</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3304705</td>\n",
       "      <td>2087</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3306526</td>\n",
       "      <td>2090</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3309092</td>\n",
       "      <td>2090</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3311343</td>\n",
       "      <td>2090</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3313549</td>\n",
       "      <td>2091</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3316519</td>\n",
       "      <td>2092</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3319146</td>\n",
       "      <td>2091</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3321635</td>\n",
       "      <td>2093</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3324611</td>\n",
       "      <td>2094</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3327683</td>\n",
       "      <td>2096</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3331052</td>\n",
       "      <td>2098</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3331052</td>\n",
       "      <td>2098</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3335704</td>\n",
       "      <td>2100</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3339653</td>\n",
       "      <td>2104</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3343685</td>\n",
       "      <td>2107</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3346412</td>\n",
       "      <td>2107</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3348952</td>\n",
       "      <td>2109</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3351502</td>\n",
       "      <td>2110</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3355287</td>\n",
       "      <td>2113</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3355287</td>\n",
       "      <td>2114</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3363102</td>\n",
       "      <td>2118</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3367243</td>\n",
       "      <td>2119</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3367243</td>\n",
       "      <td>2122</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3372972</td>\n",
       "      <td>2123</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3375730</td>\n",
       "      <td>2124</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3379522</td>\n",
       "      <td>2126</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3383486</td>\n",
       "      <td>2128</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3387252</td>\n",
       "      <td>2124</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>UC6ROKPXrnzfhNYST1w</td>\n",
       "      <td>3391743</td>\n",
       "      <td>2125</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17429</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1635546</td>\n",
       "      <td>1151</td>\n",
       "      <td>375</td>\n",
       "      <td>2017-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17430</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1635874</td>\n",
       "      <td>1152</td>\n",
       "      <td>375</td>\n",
       "      <td>2017-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17431</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1636159</td>\n",
       "      <td>1153</td>\n",
       "      <td>375</td>\n",
       "      <td>2017-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17432</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1636416</td>\n",
       "      <td>1153</td>\n",
       "      <td>375</td>\n",
       "      <td>2017-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17433</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1636416</td>\n",
       "      <td>1153</td>\n",
       "      <td>375</td>\n",
       "      <td>2017-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17434</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1636945</td>\n",
       "      <td>1153</td>\n",
       "      <td>375</td>\n",
       "      <td>2017-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17435</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1637158</td>\n",
       "      <td>1153</td>\n",
       "      <td>375</td>\n",
       "      <td>2017-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17436</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1637364</td>\n",
       "      <td>1153</td>\n",
       "      <td>375</td>\n",
       "      <td>2017-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1637594</td>\n",
       "      <td>1155</td>\n",
       "      <td>375</td>\n",
       "      <td>2017-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17438</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1637758</td>\n",
       "      <td>1155</td>\n",
       "      <td>374</td>\n",
       "      <td>2017-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17439</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1638028</td>\n",
       "      <td>1157</td>\n",
       "      <td>374</td>\n",
       "      <td>2017-03-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17440</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1638302</td>\n",
       "      <td>1159</td>\n",
       "      <td>374</td>\n",
       "      <td>2017-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17441</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1638562</td>\n",
       "      <td>1160</td>\n",
       "      <td>374</td>\n",
       "      <td>2017-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17442</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1638832</td>\n",
       "      <td>1160</td>\n",
       "      <td>374</td>\n",
       "      <td>2017-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17443</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1639075</td>\n",
       "      <td>1161</td>\n",
       "      <td>374</td>\n",
       "      <td>2017-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17444</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1639297</td>\n",
       "      <td>1161</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17445</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1639459</td>\n",
       "      <td>1161</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17446</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1640084</td>\n",
       "      <td>1161</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17447</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1640444</td>\n",
       "      <td>1161</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17448</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1640444</td>\n",
       "      <td>1162</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17449</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1641059</td>\n",
       "      <td>1162</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17450</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1641351</td>\n",
       "      <td>1162</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17451</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1641636</td>\n",
       "      <td>1162</td>\n",
       "      <td>377</td>\n",
       "      <td>2017-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17452</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1641968</td>\n",
       "      <td>1161</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17453</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1642271</td>\n",
       "      <td>1161</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17454</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1642813</td>\n",
       "      <td>1161</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17455</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1643308</td>\n",
       "      <td>1161</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17456</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1643692</td>\n",
       "      <td>1161</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17457</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1644148</td>\n",
       "      <td>1162</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17458</th>\n",
       "      <td>UC64do0QynUFrMe85Zg</td>\n",
       "      <td>1644703</td>\n",
       "      <td>1164</td>\n",
       "      <td>384</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17458 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      chid    views subcriber videocount        date\n",
       "1      UC6ROKPXrnzfhNYST1w  3302429      2087          4  2016-10-01\n",
       "2      UC6ROKPXrnzfhNYST1w  3304705      2087          4  2016-10-02\n",
       "3      UC6ROKPXrnzfhNYST1w  3306526      2090          4  2016-10-03\n",
       "4      UC6ROKPXrnzfhNYST1w  3309092      2090          4  2016-10-04\n",
       "5      UC6ROKPXrnzfhNYST1w  3311343      2090          4  2016-10-05\n",
       "6      UC6ROKPXrnzfhNYST1w  3313549      2091          4  2016-10-06\n",
       "7      UC6ROKPXrnzfhNYST1w  3316519      2092          4  2016-10-07\n",
       "8      UC6ROKPXrnzfhNYST1w  3319146      2091          4  2016-10-08\n",
       "9      UC6ROKPXrnzfhNYST1w  3321635      2093          4  2016-10-09\n",
       "10     UC6ROKPXrnzfhNYST1w  3324611      2094          4  2016-10-10\n",
       "11     UC6ROKPXrnzfhNYST1w  3327683      2096          4  2016-10-11\n",
       "12     UC6ROKPXrnzfhNYST1w  3331052      2098          4  2016-10-12\n",
       "13     UC6ROKPXrnzfhNYST1w  3331052      2098          4  2016-10-13\n",
       "14     UC6ROKPXrnzfhNYST1w  3335704      2100          4  2016-10-14\n",
       "15     UC6ROKPXrnzfhNYST1w  3339653      2104          4  2016-10-15\n",
       "16     UC6ROKPXrnzfhNYST1w  3343685      2107          4  2016-10-16\n",
       "17     UC6ROKPXrnzfhNYST1w  3346412      2107          4  2016-10-17\n",
       "18     UC6ROKPXrnzfhNYST1w  3348952      2109          4  2016-10-18\n",
       "19     UC6ROKPXrnzfhNYST1w  3351502      2110          4  2016-10-19\n",
       "20     UC6ROKPXrnzfhNYST1w  3355287      2113          4  2016-10-20\n",
       "21     UC6ROKPXrnzfhNYST1w  3355287      2114          4  2016-10-21\n",
       "22     UC6ROKPXrnzfhNYST1w  3363102      2118          4  2016-10-22\n",
       "23     UC6ROKPXrnzfhNYST1w  3367243      2119          4  2016-10-23\n",
       "24     UC6ROKPXrnzfhNYST1w  3367243      2122          4  2016-10-24\n",
       "25     UC6ROKPXrnzfhNYST1w  3372972      2123          4  2016-10-25\n",
       "26     UC6ROKPXrnzfhNYST1w  3375730      2124          4  2016-10-26\n",
       "27     UC6ROKPXrnzfhNYST1w  3379522      2126          4  2016-10-27\n",
       "28     UC6ROKPXrnzfhNYST1w  3383486      2128          4  2016-10-28\n",
       "29     UC6ROKPXrnzfhNYST1w  3387252      2124          4  2016-10-29\n",
       "30     UC6ROKPXrnzfhNYST1w  3391743      2125          4  2016-10-30\n",
       "...                    ...      ...       ...        ...         ...\n",
       "17429  UC64do0QynUFrMe85Zg  1635546      1151        375  2017-03-02\n",
       "17430  UC64do0QynUFrMe85Zg  1635874      1152        375  2017-03-03\n",
       "17431  UC64do0QynUFrMe85Zg  1636159      1153        375  2017-03-04\n",
       "17432  UC64do0QynUFrMe85Zg  1636416      1153        375  2017-03-05\n",
       "17433  UC64do0QynUFrMe85Zg  1636416      1153        375  2017-03-06\n",
       "17434  UC64do0QynUFrMe85Zg  1636945      1153        375  2017-03-07\n",
       "17435  UC64do0QynUFrMe85Zg  1637158      1153        375  2017-03-08\n",
       "17436  UC64do0QynUFrMe85Zg  1637364      1153        375  2017-03-09\n",
       "17437  UC64do0QynUFrMe85Zg  1637594      1155        375  2017-03-10\n",
       "17438  UC64do0QynUFrMe85Zg  1637758      1155        374  2017-03-11\n",
       "17439  UC64do0QynUFrMe85Zg  1638028      1157        374  2017-03-12\n",
       "17440  UC64do0QynUFrMe85Zg  1638302      1159        374  2017-03-13\n",
       "17441  UC64do0QynUFrMe85Zg  1638562      1160        374  2017-03-14\n",
       "17442  UC64do0QynUFrMe85Zg  1638832      1160        374  2017-03-15\n",
       "17443  UC64do0QynUFrMe85Zg  1639075      1161        374  2017-03-16\n",
       "17444  UC64do0QynUFrMe85Zg  1639297      1161        377  2017-03-17\n",
       "17445  UC64do0QynUFrMe85Zg  1639459      1161        377  2017-03-18\n",
       "17446  UC64do0QynUFrMe85Zg  1640084      1161        377  2017-03-19\n",
       "17447  UC64do0QynUFrMe85Zg  1640444      1161        377  2017-03-20\n",
       "17448  UC64do0QynUFrMe85Zg  1640444      1162        377  2017-03-21\n",
       "17449  UC64do0QynUFrMe85Zg  1641059      1162        377  2017-03-22\n",
       "17450  UC64do0QynUFrMe85Zg  1641351      1162        377  2017-03-23\n",
       "17451  UC64do0QynUFrMe85Zg  1641636      1162        377  2017-03-24\n",
       "17452  UC64do0QynUFrMe85Zg  1641968      1161        379  2017-03-25\n",
       "17453  UC64do0QynUFrMe85Zg  1642271      1161        379  2017-03-26\n",
       "17454  UC64do0QynUFrMe85Zg  1642813      1161        379  2017-03-27\n",
       "17455  UC64do0QynUFrMe85Zg  1643308      1161        379  2017-03-28\n",
       "17456  UC64do0QynUFrMe85Zg  1643692      1161        379  2017-03-29\n",
       "17457  UC64do0QynUFrMe85Zg  1644148      1162        379  2017-03-30\n",
       "17458  UC64do0QynUFrMe85Zg  1644703      1164        384  2017-03-31\n",
       "\n",
       "[17458 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata.drop(pdata.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_groups=pdata.groupby('chid')\n",
    "grps=[channel_groups.get_group(x) for x in channel_groups.groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def _load_data(data, n_prev = 4):  \n",
    "    \"\"\"\n",
    "    data should be pd.DataFrame()\n",
    "    \"\"\"\n",
    "\n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data)-n_prev):\n",
    "        docX.append(data.iloc[i:i+n_prev-1].as_matrix())\n",
    "        docY.append(data.iloc[i+n_prev].as_matrix())\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "\n",
    "    return alsX, alsY\n",
    "\n",
    "def train_test_split(df, test_size=0.25):  \n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"\n",
    "    ntrn = round(len(df) * (1 - test_size))\n",
    "\n",
    "    X_train, y_train = _load_data(df.iloc[0:ntrn])\n",
    "    X_test, y_test = _load_data(df.iloc[ntrn:])\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s - loss: 0.0351 - val_loss: 0.0164\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0012 - val_loss: 2.8460e-04\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 5.9335e-04 - val_loss: 1.3175e-04\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 5.2690e-04 - val_loss: 2.0015e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 6.5798e-04 - val_loss: 1.7384e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0013 - val_loss: 2.0105e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 1.5794e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0010 - val_loss: 2.1782e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 4.7162e-04 - val_loss: 3.4245e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s - loss: 0.0389 - val_loss: 0.0116\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 7.8261e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 9.9092e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 9.9452e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0010 - val_loss: 9.7077e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0020 - val_loss: 7.7363e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s - loss: 0.0274 - val_loss: 0.0195\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0075 - val_loss: 0.0031\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0060 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0052 - val_loss: 8.5871e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0051 - val_loss: 6.6613e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0057 - val_loss: 9.6844e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0049 - val_loss: 5.3706e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s - loss: 0.0913 - val_loss: 0.0251\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0233 - val_loss: 0.0276\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0149 - val_loss: 0.0183\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0140 - val_loss: 0.0191\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0136 - val_loss: 0.0197\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0137 - val_loss: 0.0162\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0140\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0084\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s - loss: 0.1074 - val_loss: 0.0313\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0383 - val_loss: 0.0056\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0195 - val_loss: 2.0927e-04\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0152 - val_loss: 0.0022\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0149 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0135 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0128 - val_loss: 0.0020\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0126 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0130 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0017\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s - loss: 0.0474 - val_loss: 0.0334\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0025 - val_loss: 7.5128e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0026 - val_loss: 7.5703e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s - loss: 0.0488 - val_loss: 0.0460\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0026 - val_loss: 9.1587e-04\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0019 - val_loss: 3.5246e-04\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0019 - val_loss: 6.7745e-04\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s - loss: 0.0015 - val_loss: 3.4723e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 4.7392e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 4.2355e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0033 - val_loss: 7.6729e-05\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 1.9887e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0263 - val_loss: 0.0309\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0082\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 4.5830e-04 - val_loss: 4.3788e-04\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 5.5519e-04 - val_loss: 1.3504e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 2.0791e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 4.3475e-04 - val_loss: 2.8848e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 3.6416e-04 - val_loss: 1.4241e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0010 - val_loss: 8.8252e-05\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 5.6843e-05\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0266 - val_loss: 0.0127\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0044 - val_loss: 0.0094\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0034 - val_loss: 0.0071\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0017 - val_loss: 7.0802e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0012 - val_loss: 6.1152e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 2.4357e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 7.0124e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0734 - val_loss: 0.0434\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0326 - val_loss: 0.0276\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0220 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0126 - val_loss: 0.0057\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0130 - val_loss: 0.0024\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0096 - val_loss: 6.3415e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0091 - val_loss: 8.4913e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0091 - val_loss: 4.9231e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0128 - val_loss: 8.7604e-05\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0091 - val_loss: 3.5668e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0387 - val_loss: 0.0829\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0190 - val_loss: 0.0450\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0160 - val_loss: 0.0301\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0149 - val_loss: 0.0250\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0122 - val_loss: 0.0193\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0237\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0188\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0110\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0259 - val_loss: 0.0124\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0035 - val_loss: 0.0013\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0219 - val_loss: 0.0162\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 7.0633e-04 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 9.0701e-04 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 5.8684e-04 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 8.7097e-04 - val_loss: 0.0016\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 6.8734e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 8.1093e-04 - val_loss: 0.0013\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0265 - val_loss: 0.0170\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0064 - val_loss: 0.0179\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0035 - val_loss: 0.0165\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0030 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0026 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0018 - val_loss: 0.0107\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0019 - val_loss: 0.0097\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0026 - val_loss: 0.0100\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0017 - val_loss: 0.0083\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 0.0077\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0710 - val_loss: 0.0422\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0303 - val_loss: 0.0369\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0232 - val_loss: 0.0327\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0217 - val_loss: 0.0252\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0195\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0201 - val_loss: 0.0169\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0194 - val_loss: 0.0149\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0146\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0148\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0181 - val_loss: 0.0141\n",
      "Train on 24 samples, validate on 2 samples\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 1s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0547 - val_loss: 0.0376\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0159 - val_loss: 0.0195\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0209\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0210\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0174\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0144\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0078 - val_loss: 0.0123\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0078 - val_loss: 0.0113\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0072 - val_loss: 0.0101\n",
      "Train on 23 samples, validate on 2 samples\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 1s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0579 - val_loss: 0.0424\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0216 - val_loss: 0.0374\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0143 - val_loss: 0.0307\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0126 - val_loss: 0.0250\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0209\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0182\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0159\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0092\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0270 - val_loss: 0.0292\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0150\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 7.8524e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0012 - val_loss: 9.1556e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0395 - val_loss: 0.0171\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0152 - val_loss: 0.0141\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0120\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0074 - val_loss: 0.0088\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0043 - val_loss: 7.4102e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0037 - val_loss: 4.6790e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0036 - val_loss: 2.2576e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0219 - val_loss: 0.0159\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0021 - val_loss: 8.5531e-04\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 4.1566e-04 - val_loss: 4.1785e-04\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 4.5511e-04 - val_loss: 3.3945e-04\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 6.4116e-04 - val_loss: 5.5287e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 8.5999e-04 - val_loss: 4.3759e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 5.4926e-04 - val_loss: 4.9529e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0010 - val_loss: 4.0698e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 5.0337e-04 - val_loss: 5.8536e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 7.4914e-04 - val_loss: 3.1124e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0314 - val_loss: 0.0281\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 9.9105e-04 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 4.9526e-04 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 4.9874e-04 - val_loss: 0.0028\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 9.6408e-04 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 5.8210e-04 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 9.0949e-04 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 8.8384e-04 - val_loss: 0.0020\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: 0.0506 - val_loss: 0.0228\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0040 - val_loss: 0.0026\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0239 - val_loss: 0.0350\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 2.1345e-04\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s - loss: 8.2787e-04 - val_loss: 4.3378e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 9.5126e-04 - val_loss: 9.9919e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 6.8768e-04 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 7.4535e-04 - val_loss: 0.0018\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0553 - val_loss: 0.0117\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0159 - val_loss: 0.0042\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0130 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0134 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0125 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0116 - val_loss: 6.5544e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0137 - val_loss: 7.1422e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0101 - val_loss: 9.7202e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0118 - val_loss: 5.1548e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0107 - val_loss: 6.7550e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0121 - val_loss: 0.0256\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0046 - val_loss: 0.0200\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0037 - val_loss: 0.0157\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0033 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0029 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0029 - val_loss: 0.0110\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0028 - val_loss: 0.0112\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0032 - val_loss: 0.0111\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0033 - val_loss: 0.0101\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0027 - val_loss: 0.0103\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0344 - val_loss: 0.0298\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0137 - val_loss: 0.0167\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0071 - val_loss: 0.0016\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0067 - val_loss: 0.0014\n",
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s - loss: 0.0120 - val_loss: 0.0048\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s - loss: 0.0024 - val_loss: 0.0087\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s - loss: 0.0025 - val_loss: 0.0066\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s - loss: 0.0018 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s - loss: 0.0014 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s - loss: 0.0012 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s - loss: 0.0011 - val_loss: 0.0063\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0161 - val_loss: 0.0103\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0017 - val_loss: 9.4380e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0015 - val_loss: 7.0275e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 8.3765e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 6.6551e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0015 - val_loss: 7.9806e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 9.5272e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 3s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0505 - val_loss: 0.0390\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0136 - val_loss: 0.0141\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 8.4832e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 9.5103e-04 - val_loss: 9.6962e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 8.3585e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 8.6783e-04 - val_loss: 9.6591e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0788 - val_loss: 0.0460\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s - loss: 0.0269 - val_loss: 0.0214\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0140 - val_loss: 0.0126\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0070\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0013\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 74 samples, validate on 4 samples\n",
      "Epoch 1/10\n",
      "74/74 [==============================] - 2s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0753 - val_loss: 0.0511\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0216 - val_loss: 0.0102\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0134 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0113 - val_loss: 2.7046e-04\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0106 - val_loss: 2.0426e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0095 - val_loss: 1.9024e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0096 - val_loss: 2.9764e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0084 - val_loss: 7.4481e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0078 - val_loss: 5.2046e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0472 - val_loss: 0.0156\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0024\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0011\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 4s - loss: 0.0411 - val_loss: 0.0216\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0026 - val_loss: 8.5919e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0018 - val_loss: 6.6017e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0016 - val_loss: 6.3757e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0018 - val_loss: 8.2626e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0703 - val_loss: 0.0397\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0191 - val_loss: 0.0094\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0036 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0034 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0038 - val_loss: 0.0107\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0041 - val_loss: 0.0117\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0036 - val_loss: 0.0102\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0036 - val_loss: 0.0090\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0314 - val_loss: 0.0234\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0067 - val_loss: 0.0098\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0013 - val_loss: 9.2286e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0384 - val_loss: 0.0467\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0126 - val_loss: 0.0204\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0079 - val_loss: 0.0027\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0075 - val_loss: 7.7052e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0077 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0069 - val_loss: 8.4964e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0066 - val_loss: 7.2765e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0069 - val_loss: 0.0014\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 3s - loss: 0.0367 - val_loss: 0.0341\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0024 - val_loss: 9.1222e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0025 - val_loss: 9.3550e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0022 - val_loss: 6.7470e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0022 - val_loss: 0.0018\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0325 - val_loss: 0.0356\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0127\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 5.7347e-04\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 8.1052e-04 - val_loss: 6.5357e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 8.0926e-04 - val_loss: 5.9112e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 6.2494e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0015 - val_loss: 3.5313e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 9.3713e-04 - val_loss: 5.3835e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 5.4973e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0649 - val_loss: 0.0401\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0140 - val_loss: 0.0085\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0039 - val_loss: 0.0019\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0208 - val_loss: 0.0216\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 8.5518e-04 - val_loss: 4.8314e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 7.1248e-04 - val_loss: 1.9551e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 6.3004e-04 - val_loss: 1.4899e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 1.2783e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 1.0231e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 9.9027e-04 - val_loss: 6.5021e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0402 - val_loss: 0.0345\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0027 - val_loss: 0.0015\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0245 - val_loss: 0.0111\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0027 - val_loss: 3.2239e-04\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0021 - val_loss: 3.2126e-04\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0021 - val_loss: 2.4078e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0026 - val_loss: 1.7058e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0022 - val_loss: 2.0093e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0017 - val_loss: 2.0986e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0017 - val_loss: 1.4931e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0022 - val_loss: 2.2489e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0322 - val_loss: 0.0320\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0158\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 9.0237e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 2s - loss: 0.0810 - val_loss: 0.0180\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0131 - val_loss: 0.0067\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0136 - val_loss: 0.0091\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0127 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0038\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 3s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 3s - loss: 0.0642 - val_loss: 0.1055\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0252 - val_loss: 0.0672\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0147 - val_loss: 0.0382\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0206\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 0.0078 - val_loss: 0.0027\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 0.0070 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 0.0072 - val_loss: 7.5181e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0072 - val_loss: 0.0022\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 3s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 3s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: nan - val_loss: nan\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 3s - loss: 0.0234 - val_loss: 0.0242\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 8.5471e-04\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s - loss: 0.0011 - val_loss: 2.9168e-04\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s - loss: 8.4959e-04 - val_loss: 8.1309e-04\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s - loss: 7.2545e-04 - val_loss: 3.9056e-04\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s - loss: 0.0012 - val_loss: 4.8876e-04\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s - loss: 6.2433e-04 - val_loss: 1.0158e-04\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s - loss: 9.5355e-04 - val_loss: 5.7524e-04\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s - loss: 0.0014 - val_loss: 9.9546e-04\n",
      "Train on 125 samples, validate on 7 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Activation  \n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "import numpy as np\n",
    "for i in range(len(grps)-1):\n",
    "    p=grps[i]\n",
    "    p=p.sort_values(by='date')\n",
    "    del p['date']\n",
    "    del p['chid']\n",
    "    p['views']=p['views'].astype(float)\n",
    "    views_range=p['views'].max()- p['views'].min()\n",
    "    views_average=np.asarray(p['views'], dtype=np.float).mean()\n",
    "    p['views']= (p['views'] - views_average )/ views_range\n",
    "    p['subcriber']=p['subcriber'].astype(int)\n",
    "    subcriber_range=p['subcriber'].max() - p['subcriber'].min()\n",
    "    subcriber_average=np.asarray(p['subcriber'], dtype=np.float).mean()\n",
    "    p['subcriber']= (p['subcriber'] - np.asarray(p['subcriber'], dtype=np.float).mean()) / (p['subcriber'].max() - p['subcriber'].min())\n",
    "    p['videocount']=p['videocount'].astype(int)\n",
    "    videocount_range=p['videocount'].max() - p['videocount'].min()\n",
    "    videocount_average=np.asarray(p['videocount'], dtype=np.float).mean()\n",
    "    p['videocount']= (p['videocount'] - np.asarray(p['videocount'], dtype=np.float).mean()) / (p['videocount'].max() - p['videocount'].min())\n",
    "    (X_train, y_train), (X_test, y_test) = train_test_split(p)  # retrieve data\n",
    "    X_train=X_train.reshape((-1,3,3))\n",
    "    in_out_neurons = 3  \n",
    "\n",
    "    hidden_neurons = 300\n",
    "\n",
    "\n",
    "    model = Sequential()  \n",
    "\n",
    "    model.add(LSTM(input_shape=(3,3),units=hidden_neurons, return_sequences=False))  \n",
    "\n",
    "    model.add(Dense(units=10))  \n",
    "\n",
    "\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "\n",
    "    model.add(Dense(units=3))\n",
    "\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")  \n",
    "    model.fit(x=X_train, y=y_train,validation_split=0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, date\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "start_date = date(2017, 4, 1)\n",
    "end_date = date(2017, 7, 1)\n",
    "p=np.empty((100,3,3))\n",
    "predicted=np.empty((100,3))\n",
    "p[0]=grps[len(grps)-1].iloc[-3:].reshape((1,3,3))\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    p[i][0]=p[i-1][1]\n",
    "    p[i][1]=p[i-1][2]\n",
    "    p[i][2]=model.predict(p[i-1].reshape((1,3,3)))\n",
    "    predicted[i]=p[i][2]\n",
    "    print (single_date,predicted[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
